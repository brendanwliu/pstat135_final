{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5, rc={'text.usetex' : True})\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "path = \"./input/clean/training_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+--------------------+------------------+------------------+------------------+\n",
      "|             ATemp|           MaxTemp|           MinTemp|               RH|            MaxRH|            MinRH|                BP|             MaxBP|             MinBP|              WSpd|              Wdir|            SDWDir|           MaxWSpd|            MinWSpd|             TotPrcp|            TotPAR|           AvgVolt|              Temp|\n",
      "+------------------+------------------+------------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+--------------------+------------------+------------------+------------------+\n",
      "| 8.296874999999998| 8.633333333333333|          7.971875|71.97916666666667|74.14583333333333|         69.71875|           1027.75|        1028.96875|1027.5833333333333|1.3093750000000004|249.76041666666666|             17.25|2.3927083333333328|0.43541666666666656|                 0.0|204.30624999999995|13.016666666666666|10.641145833333328|\n",
      "|11.064583333333331|11.410416666666663|10.726041666666669|71.29166666666667|73.47916666666667|68.89583333333333|1024.4583333333333|        1025.78125|1024.2708333333333|1.7385416666666673|249.57291666666666|16.197916666666668|3.0718750000000004| 0.6895833333333332|0.003124999999999...|173.65000000000006|12.969791666666666|11.089062499999999|\n",
      "|15.534374999999997|15.804166666666665|15.269791666666672|          71.1875|         72.21875|         70.21875|            1021.5|1022.5520833333334|1021.1770833333334|            3.0625|         243.15625|12.020833333333334| 5.442708333333333| 1.2510416666666666|                 0.0|205.38749999999993|12.962499999999999|12.167708333333321|\n",
      "|19.130208333333332|19.364583333333332|18.907291666666655|         74.09375|         74.96875|73.23958333333333|1019.2395833333334|1020.2291666666666|1019.0833333333334|3.7354166666666675|236.16666666666666|          12.96875| 7.070833333333334|  1.435416666666667|                 0.0|182.80312500000005|12.883333333333338|13.960937499999993|\n",
      "|19.667708333333334|19.879166666666663|19.453124999999993|          84.5625|85.16666666666667|83.88541666666667|           1015.25|         1016.4375|         1014.9375| 5.346875000000001|233.16666666666666|          13.65625|10.288541666666669| 1.9677083333333332|                 0.0| 204.1947916666666|12.938541666666664|15.548437499999999|\n",
      "+------------------+------------------+------------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+--------------------+------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NC_data = spark.read.csv(path + \"NOAA_NC_DAvg_training_data.csv\", header=True, inferSchema=True)\n",
    "NC_data = NC_data.drop(*[t for t in NC_data.columns if t[-1] == 'T']+['date','CLASS'])\n",
    "NC_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|             label|\n",
      "+--------------------+------------------+\n",
      "|[8.29687499999999...|10.641145833333328|\n",
      "|[11.0645833333333...|11.089062499999999|\n",
      "|[15.5343749999999...|12.167708333333321|\n",
      "|[19.1302083333333...|13.960937499999993|\n",
      "|[19.6677083333333...|15.548437499999999|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vector of features\n",
    "rf = RFormula(formula=\"Temp~.\")\n",
    "vector_rf = rf.fit(NC_data).transform(NC_data).select([\"features\",\"label\"])\n",
    "vector_rf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+--------------------+\n",
      "|        prediction|            label|            features|\n",
      "+------------------+-----------------+--------------------+\n",
      "|  7.70186497124369|5.170833333333334|[-3.7364583333333...|\n",
      "|  6.33642535087859|7.708333333333331|[0.36562500000000...|\n",
      "| 6.033975011571917|6.215624999999999|[0.94270833333333...|\n",
      "|6.3316424820201265|5.864583333333335|[1.20937500000000...|\n",
      "|  5.40155232311758|7.271354166666668|[1.32083333333333...|\n",
      "+------------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 1.95293\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "train, test = vector_rf.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTRegressor(featuresCol=\"features\", maxIter=10, seed = 1230)\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = gbt.fit(train)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mmlspark.lightgbm._LightGBMRegressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-462e0966d2b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmlspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightGBMRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m lgb = LightGBMRegressor(\n\u001b[1;32m      4\u001b[0m   \u001b[0mnumIterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mlearningRate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/mmlspark/lightgbm/LightGBMRegressor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbasestring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmlspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LightGBMRegressor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LightGBMRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmlspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LightGBMRegressor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LightGBMRegressionModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mmlspark.lightgbm._LightGBMRegressor'"
     ]
    }
   ],
   "source": [
    "from mmlspark.lightgbm import LightGBMRegressor\n",
    "\n",
    "lgb = LightGBMRegressor(\n",
    "  numIterations=500,\n",
    "  learningRate=0.05\n",
    ")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lgb.numLeaves, range(10,200,1))\n",
    "             .addGrid(lgb.maxDepth, range(1,15,1))\n",
    "             .addGrid(lgb.baggingFraction, np.arange(0,1,0.01))\n",
    "             ,addGrid(lgb.featureFraction, np.arange(0,1,0.01))\n",
    "             .addGrid(lgb.minSumHessianInLeaf, np.arrange(0.0005,0.01,0.0001))\n",
    "             .addGrid(lgb.lambdaL1, range(0,20000000,1))\n",
    "             .addGrid(lgb.lambdaL2, range(0,20000000,1))\n",
    "             .build())\n",
    "\n",
    "evaluator=RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "cv = CrossValidator(estimator=lgb, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "cvModel_lgb = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('tf_gpu': conda)",
   "language": "python",
   "name": "python37364bittfgpuconda7e668d0e657f454088b0edd105307237"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
